{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VwZB88q_HEDw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lulu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1VnCtVEiHEDy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: torchmetrics in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.10.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torchmetrics) (2.4.1)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions; python_version < \"3.9\" in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torchmetrics) (4.12.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>1.20.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torchmetrics) (1.23.5)\n",
      "Requirement already satisfied, skipping upgrade: packaging>17.1 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torchmetrics) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: lightning-utilities>=0.8.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torchmetrics) (0.11.9)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2.11.1)\n",
      "Requirement already satisfied, skipping upgrade: fsspec in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: networkx in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: filelock in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: sympy in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from packaging>17.1->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from packaging>17.1->torchmetrics) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from networkx->torch>=1.10.0->torchmetrics) (4.4.1)\n",
      "Requirement already satisfied, skipping upgrade: mpmath>=0.19 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8038b6_mHbBa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: IPython in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from import-ipynb) (7.12.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from import-ipynb) (5.0.4)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from IPython->import-ipynb) (0.14.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from IPython->import-ipynb) (4.3.3)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from IPython->import-ipynb) (0.4.3)\n",
      "Requirement already satisfied: pygments in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from IPython->import-ipynb) (2.5.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from IPython->import-ipynb) (3.0.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from IPython->import-ipynb) (0.1.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from IPython->import-ipynb) (4.4.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from IPython->import-ipynb) (45.2.0.post20200210)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from IPython->import-ipynb) (0.7.5)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from nbformat->import-ipynb) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from nbformat->import-ipynb) (4.6.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from nbformat->import-ipynb) (0.2.0)\n",
      "Requirement already satisfied: parso>=0.5.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from jedi>=0.10->IPython->import-ipynb) (0.5.2)\n",
      "Requirement already satisfied: six in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from traitlets>=4.2->IPython->import-ipynb) (1.14.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import-ipynb) (0.2.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->import-ipynb) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->import-ipynb) (0.15.7)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from jupyter-core->nbformat->import-ipynb) (227)\n"
     ]
    }
   ],
   "source": [
    "!pip install import-ipynb\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f2xWhGhLSfJo"
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import torch                           #optimized tensor library for deeplearning\n",
    "from torch.utils.data import Dataset   #torch.utils.data --- data loading utility. map-style(random) or iterable style; dataset ---- abstract class representing a dataset\n",
    "from torch.autograd import Variable    #classes and functions implementing automatic differentiation of arbitrary scalar valued functions\n",
    "import torch.nn as nn                  #basic building block for graphs\n",
    "import torch.nn.functional as F        #convolution fn, pooling fn...\n",
    "import torch.optim as optim            #implementing various optimization algorithm\n",
    "import os                              #functions for interacting with os\n",
    "import time\n",
    "\n",
    "from torch.nn import BatchNorm1d\n",
    "#provides time related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hrxUq8NqHED9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pyg-lib (from versions: none)\n",
      "ERROR: No matching distribution found for pyg-lib\n"
     ]
    }
   ],
   "source": [
    "!pip install pyg-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Qv6pnV4THED9",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch-geometric) (0.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch-geometric) (4.42.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch-geometric) (3.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch-geometric) (1.23.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch-geometric) (2.23.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from torch-geometric) (2.11.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from aiohttp->torch-geometric) (19.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from aiohttp->torch-geometric) (1.4.2)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from aiohttp->torch-geometric) (4.7.5)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from aiohttp->torch-geometric) (3.0.1)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from aiohttp->torch-geometric) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->torch-geometric) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->torch-geometric) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->torch-geometric) (1.25.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lulu\\anaconda3\\envs\\venv\\lib\\site-packages (from jinja2->torch-geometric) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YyqRM6vxHED-"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import datasets\n",
    "from numpy import count_nonzero\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1NuU5_EoHED-"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.batch import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OYEb8kWbHED-"
   },
   "outputs": [],
   "source": [
    "input_size=186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fRtT7XELHED-"
   },
   "outputs": [],
   "source": [
    "from torchmetrics.functional.regression import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JxI2nwSMvmJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6t63aC-nMweb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbohyYSiNbkb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d70z6zmcyfm"
   },
   "source": [
    "# Using Pathway Pathway Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MiOxen0SNbM0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3eKMnKodNTY"
   },
   "source": [
    "# Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "A98RRKBPPV-2"
   },
   "outputs": [],
   "source": [
    "# Load pathway-gene associations\n",
    "pathway_array = np.loadtxt('kegg_pathway_interaction_186x186.txt')\n",
    "pathway_cell_gene_arr_new = torch.tensor(pathway_array, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Xm-TNiurPbFC"
   },
   "outputs": [],
   "source": [
    "# Build pathway to gene mapping\n",
    "def build_pathway_dict(pathway_array):\n",
    "    pathway_dic_new = {}\n",
    "    for i in range(pathway_array.shape[0]):\n",
    "        genes = [j for j in range(pathway_array.shape[1]) if pathway_array[i, j] == 1]\n",
    "        if genes:\n",
    "            pathway_dic_new[i] = genes\n",
    "    return pathway_dic_new\n",
    "\n",
    "pathway_dic_new = build_pathway_dict(pathway_array)\n",
    "num_pathways = len(pathway_dic_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "UklkPHRbPjJV"
   },
   "outputs": [],
   "source": [
    "# Load edge connections (symmetric matrix: interaction between pathways)\n",
    "edge_array = np.loadtxt('kegg_pathway_interaction_186x186.txt')\n",
    "edge_start, edge_end = [], []\n",
    "for i in range(edge_array.shape[0]):\n",
    "    for j in range(edge_array.shape[1]):\n",
    "        if edge_array[i][j] != 0:\n",
    "            edge_start.append(i)\n",
    "            edge_end.append(j)\n",
    "\n",
    "graphs = []\n",
    "for i in range(num_pathways):\n",
    "    gene_indices = pathway_dic_new[i]\n",
    "    num_nodes = len(gene_indices)\n",
    "    if num_nodes == 0:\n",
    "        continue\n",
    "\n",
    "    # Dummy placeholder features (replaced per sample)\n",
    "    x = torch.randn((num_nodes, 1), dtype=torch.float32)\n",
    "\n",
    "    # Create fully connected subgraph for now (can be updated)\n",
    "    edge_index = torch.combinations(torch.arange(num_nodes), r=2).t()\n",
    "    edge_index = torch.cat([edge_index, edge_index[[1, 0]]], dim=1)  # undirected\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    graphs.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdNtVfF1dYnW"
   },
   "source": [
    "# GCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "yojMfx4GPo32"
   },
   "outputs": [],
   "source": [
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=16, output_dim=8):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "DffO2JcfPrnb"
   },
   "outputs": [],
   "source": [
    "# One model per pathway graph\n",
    "gcn_models = [GCN() for _ in range(num_pathways)]\n",
    "optimizers = [torch.optim.Adam(model.parameters(), lr=0.01) for model in gcn_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "LcBnXVc-Pu0D"
   },
   "outputs": [],
   "source": [
    "# Load gene expression samples\n",
    "sample_df = pd.read_csv('train_set1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "VtkHQHtrMz5U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "Finished GCN training for all graphs.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train loop: for each sample, update each graph\n",
    "for epoch in range(1):  # small number of epochs for illustration\n",
    "    print(\"epoch \",epoch)\n",
    "    for sample_idx in range(sample_df.shape[0]):\n",
    "        sample = sample_df.iloc[sample_idx]  # expression values\n",
    "\n",
    "        for i in range(num_pathways):\n",
    "            gene_indices = pathway_dic_new[i]\n",
    "            if not gene_indices:\n",
    "                continue\n",
    "\n",
    "            # Get node features from sample expression values\n",
    "            node_feats = sample.iloc[gene_indices].values.reshape(-1, 1)\n",
    "            node_feats = torch.tensor(node_feats, dtype=torch.float32)\n",
    "\n",
    "            # Update node features in graph\n",
    "            graphs[i].x = node_feats\n",
    "\n",
    "            # Forward and optimize\n",
    "            model = gcn_models[i]\n",
    "            optimizer = optimizers[i]\n",
    "\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(graphs[i].x, graphs[i].edge_index)\n",
    "\n",
    "            # Dummy target: just sum node embeddings to some constant value for illustrative loss\n",
    "            # target = torch.ones(out.shape[0], 8)\n",
    "            # loss = F.mse_loss(out, target)\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "\n",
    "print(\"Finished GCN training for all graphs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiK89zZVdevB"
   },
   "source": [
    "# Taking Mean to form a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "vemU7D40TKCN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([186])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# graph_list is the list containing 186 graphs with updated node features\n",
    "mean_features = []\n",
    "\n",
    "for graph in graphs:\n",
    "    # graph.x contains the node features of that graph\n",
    "    node_mean = torch.mean(graph.x, dim=0)  # Mean over all nodes\n",
    "    # If node features are vectors (e.g., dim > 1), you might choose to reduce further:\n",
    "    # node_mean = node_mean.mean()  # To get a single scalar value\n",
    "    mean_features.append(node_mean)\n",
    "\n",
    "# Convert to tensor (optional)\n",
    "mean_features_tensor = torch.stack(mean_features)  # Shape: (186, feature_dim)\n",
    "\n",
    "# If you want just one value per graph (e.g., to get (186,) shape), reduce further\n",
    "mean_scalar_features = mean_features_tensor.mean(dim=1)  # Shape: (186,)\n",
    "\n",
    "print(mean_scalar_features.shape)  # Should be: torch.Size([186])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XNPOCJqteOI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "IYcMCxnTTXtG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(186, 186)\n",
      "1364\n",
      "1364\n",
      "1364\n"
     ]
    }
   ],
   "source": [
    "edge_array1 = np.loadtxt('kegg_pathway_interaction_186x186.txt')\n",
    "\n",
    "print(edge_array1)\n",
    "print(edge_array1.shape)\n",
    "\n",
    "edge_start=[]\n",
    "edge_end=[]\n",
    "edge_weight=[]\n",
    "\n",
    "for i in range(edge_array1.shape[0]):    #323\n",
    "    for j in range(edge_array1.shape[1]):\n",
    "        if(edge_array1[i][j]!= 0):\n",
    "                edge_start.append(i)\n",
    "                edge_end.append(j)\n",
    "                edge_weight.append(edge_array1[i][j])\n",
    "\n",
    "\n",
    "\n",
    "print(len(edge_start))\n",
    "print(len(edge_end))\n",
    "print(len(edge_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "sTHN17M5e_XC"
   },
   "outputs": [],
   "source": [
    "#set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # if GPU available run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "-JHcopFRWUp1"
   },
   "outputs": [],
   "source": [
    "# Convert edge list and weights to tensors\n",
    "edge_index = torch.tensor([edge_start, edge_end], dtype=torch.long)  # shape: [2, num_edges]\n",
    "edge_weight = torch.tensor(edge_weight, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "i80y2PhVWKbi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[186, 1], edge_index=[2, 1364], edge_attr=[1364])\n"
     ]
    }
   ],
   "source": [
    "pathway_features = mean_scalar_features\n",
    "# 2. Use the 186 pathway-level features (mean node features from individual pathway graphs)\n",
    "# pathway_features = torch.rand(186, 1)  # shape: [186, 1]\n",
    "\n",
    "if pathway_features.dim() == 1:\n",
    "    pathway_features = pathway_features.unsqueeze(1)\n",
    "\n",
    "# 3. Create the pathway graph\n",
    "pathway_graph = Data(x=pathway_features, edge_index=edge_index, edge_attr=edge_weight)\n",
    "\n",
    "print(pathway_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NivBYEZodnkq"
   },
   "source": [
    "# Passing through GCN to get array of 128 G2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "jRWLqqPlBTEI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "# === Your GCN model ===\n",
    "class FinalGraphGCN(nn.Module):\n",
    "    def __init__(self, in_channels=1, hidden_channels=64, out_channels=128):\n",
    "        super(FinalGraphGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        graph_embeddings = global_mean_pool(x, batch)  # Mean pooling per graph\n",
    "        return graph_embeddings  # Shape: [batch_size, 128]\n",
    "\n",
    "\n",
    "batched_graphs = [Data(x=pathway_graph.x.clone(),\n",
    "                       edge_index=pathway_graph.edge_index.clone())\n",
    "                  for _ in range(batch_size)]\n",
    "\n",
    "# Load into a DataLoader\n",
    "loader = DataLoader(batched_graphs, batch_size=128, shuffle=False)\n",
    "\n",
    "# Instantiate model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FinalGraphGCN().to(device)\n",
    "\n",
    "# === Pass through GCN ===\n",
    "for batch in loader:\n",
    "    batch = batch.to(device)\n",
    "    output_embeddings = model(batch.x, batch.edge_index, batch.batch)\n",
    "    print(\"Output shape:\", output_embeddings.shape)  # [128, 128]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qagz9NJDXIYP"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # === Define the GCN Model ===\n",
    "# class FinalGraphGCN(nn.Module):\n",
    "#     def __init__(self, in_channels=1, hidden_channels=64, out_channels=128):\n",
    "#         super(FinalGraphGCN, self).__init__()\n",
    "#         self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "#         self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         graph_embedding = x.mean(dim=0)  # Mean-pool across nodes\n",
    "#         return graph_embedding  # Shape: [128]\n",
    "\n",
    "\n",
    "# # === Pass through GCN ===\n",
    "# model = FinalGraphGCN()\n",
    "# final_graph_embedding = model(pathway_graph.x, pathway_graph.edge_index)\n",
    "# final_graph_embedding = final_graph_embedding.to(device)\n",
    "\n",
    "# print(\"Output shape:\", final_graph_embedding.shape)  # Should be: torch.Size([128])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsTIUp-guBsc"
   },
   "source": [
    "# G1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "aLm8a4jVG1tw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # === Simulate batch of 128 samples ===\n",
    "# # Each sample is a feature vector of size 186\n",
    "# batch_size = 128\n",
    "# input_dim = 186\n",
    "# output_dim = 128\n",
    "\n",
    "# # Example input: batch of 128 samples, each with 186 features\n",
    "# # (This would come from your precomputed mean_scalar_features for each graph in a batch)\n",
    "# mean_scalar_features = torch.randn(batch_size, input_dim)  # Shape: (128, 186)\n",
    "\n",
    "# # Move to device (if using GPU)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# mean_scalar_features = mean_scalar_features.to(device)\n",
    "\n",
    "# # === Define FC layer: 186 → 128 ===\n",
    "# fc_layer = nn.Linear(input_dim, output_dim)\n",
    "# fc_layer = fc_layer.to(device)\n",
    "\n",
    "# # === Pass through FC layer ===\n",
    "# output_vectors = fc_layer(mean_scalar_features)  # Shape: (128, 128)\n",
    "\n",
    "# print(\"Output shape:\", output_vectors.shape)        # torch.Size([128, 128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([128, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Real feature of shape (186,)\n",
    "feature_186 = mean_scalar_features  # Replace this with your real computed vector\n",
    "\n",
    "# Expand and repeat to simulate batch of 128\n",
    "batch_size = 128\n",
    "feature_batch = feature_186.unsqueeze(0).repeat(batch_size, 1)  # Shape: (128, 186)\n",
    "\n",
    "# Move to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "feature_batch = feature_batch.to(device)\n",
    "\n",
    "# Define FC layer: 186 → 128\n",
    "fc_layer = nn.Linear(186, 128).to(device)\n",
    "\n",
    "# Pass through FC layer\n",
    "output_vectors = fc_layer(feature_batch)  # Shape: (128, 128)\n",
    "\n",
    "print(\"Output shape:\", output_vectors.shape)  # torch.Size([128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGRYHEbRt7s5"
   },
   "outputs": [],
   "source": [
    "# mean_scalar_features = mean_scalar_features.view(1, -1).float()  # Shape: (1, 186)\n",
    "\n",
    "# # Define the fully connected layer: 186 → 128\n",
    "# fc_layer = nn.Linear(186, 128)\n",
    "\n",
    "# # Pass through the FC layer\n",
    "# output_vector = fc_layer(mean_scalar_features)  # Shape: (1, 128)\n",
    "\n",
    "# # Remove batch dim if needed\n",
    "# output_vector = output_vector  # Shape: (128,)\n",
    "# output_vector = output_vector.to(device)\n",
    "\n",
    "# print(output_vector.shape)  # Should print: torch.Size([128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yH67AfQTejK8"
   },
   "source": [
    "# Cell line Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "wgK0D0T0aU8F"
   },
   "outputs": [],
   "source": [
    "num_cellline_genes = 4603 # 537\n",
    "num_drug_genes = 4603#741\n",
    "num_drug_fp=512\n",
    "num_pathways = 186 #323\n",
    "TINY = 1e-15\n",
    "# TRAIN_NUM = 197957\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "time_start=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "3EynjHXmeqkN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# �������ݼ�������data_loader\n",
    "class DrugCellAUC(Dataset):\n",
    "    \"\"\"Drug Disease Interaction dataset.\"\"\"\n",
    "    def __init__(self, file_name, transform=None):\n",
    "        self.pairs = []\n",
    "        self.aucs = []\n",
    "\n",
    "\n",
    "        mostline = 0\n",
    "        with open(file_name, 'r') as f:\n",
    "            for line in f:\n",
    "                mostline += 1\n",
    "                items = line.strip().split(',')\n",
    "                cellLineId, drugId, auc, genes = items[0], items[1], items[2], items[3:]\n",
    "                cell_drug_gene = [float(x) for x in genes[:num_cellline_genes + num_drug_genes]]\n",
    "                assert len(cell_drug_gene) == num_cellline_genes + num_drug_fp\n",
    "                cell_drug_gene = torch.Tensor(cell_drug_gene).cpu()\n",
    "                self.pairs.append(cell_drug_gene)\n",
    "                self.aucs.append(float(auc))\n",
    "                # if mostline == TRAIN_NUM:\n",
    "                #     break\n",
    "        self.aucs = torch.FloatTensor(self.aucs).cpu()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % len(self)\n",
    "        cell_drug_gene = self.pairs[idx]\n",
    "        auc = self.aucs[idx]\n",
    "        return cell_drug_gene, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "yBh2iBsbe4Yr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 4603)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_relations = []\n",
    "with open('pathway_commongene.csv','r') as f:\n",
    "    for line in f:\n",
    "        _relation = line.strip().split(',')\n",
    "#         print(len(_relation))\n",
    "        all_relations.append(_relation)\n",
    "\n",
    "pathway_cell_gene_arr=np.array(all_relations)\n",
    "pathway_cell_gene_arr = pathway_cell_gene_arr.astype(np.uint8) # convert to int\n",
    "# pathway_gene_arr = pathway_gene_arr.astype(np.float)\n",
    "# print(pathway_cell_gene_arr[1,:])\n",
    "print(pathway_cell_gene_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Qj7OvVUmfJi5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4603, 165)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Displaying the contents of the text file\n",
    "PPI_f = np.loadtxt('ppi_gte400_commongene4603x4603.txt',  usecols=range(165))\n",
    "# print(\"\\nContent in file1.txt:\\n\", pathway_gene[1,:])\n",
    "\n",
    "print(PPI_f.shape)\n",
    "\n",
    "## considered ppi score>=400 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "yG2jHSQKHED9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "t4J_MrvYCdGf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c9d3c4f270>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import MaskedLinear1\n",
    "#MaskedLinear1.MaskedLinear\n",
    "# import cacul_r2\n",
    "# cacul_r2.cacul_r\n",
    "import cacul_r3\n",
    "cacul_r3.cacul_r\n",
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "bFfVoENUHED9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4956\n",
      "0\n",
      "754539\n"
     ]
    }
   ],
   "source": [
    "ppi_edge_array_norm = PPI_f\n",
    "\n",
    "c=0\n",
    "d=0\n",
    "f=0\n",
    "for i in range(ppi_edge_array_norm.shape[0]):    #323\n",
    "\n",
    "    for k in range(ppi_edge_array_norm.shape[1]):    #323\n",
    "#         if(ppi_edge_array_norm[i][k]!=0):\n",
    "        if(ppi_edge_array_norm[i][k]>=0.7):\n",
    "            c=c+1\n",
    "            if(ppi_edge_array_norm[i][k]>1):\n",
    "                f=f+1\n",
    "        else:\n",
    "            d=d+1\n",
    "print(c)\n",
    "print(f)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "vSeBUBeeHED9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4956\n",
      "4956\n",
      "4956\n"
     ]
    }
   ],
   "source": [
    "ppi_edge_start=[]\n",
    "ppi_edge_end=[]\n",
    "ppi_edge_weight=[]\n",
    "\n",
    "for i in range(ppi_edge_array_norm.shape[0]):    #323\n",
    "    for j in range(ppi_edge_array_norm.shape[1]):\n",
    "#         if(ppi_edge_array_norm[i][j]!= 0):\n",
    "        if(ppi_edge_array_norm[i][j]>=0.7):\n",
    "#             if(i!=j):\n",
    "                ppi_edge_start.append(i)\n",
    "                ppi_edge_end.append(j)\n",
    "                ppi_edge_weight.append(ppi_edge_array_norm[i][j])\n",
    "#                 edge_start.append(i)\n",
    "#                 edge_end.append(j)\n",
    "#                 edge_weight.append(edge_array_norm[i][j])\n",
    "#             else:\n",
    "#                 edge_start.append(i)\n",
    "#                 edge_end.append(j)\n",
    "#                 edge_weight.append(edge_array_norm[i][j])\n",
    "\n",
    "\n",
    "\n",
    "print(len(ppi_edge_start))\n",
    "print(len(ppi_edge_end))\n",
    "print(len(ppi_edge_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "MLWLgDfOHED9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    1,  ..., 4597, 4597, 4602],\n",
      "        [   0,   79,    1,  ...,  130,  155,   40]])\n",
      "tensor([1.0000, 0.9000, 1.0000,  ..., 0.9430, 0.9380, 0.9990])\n"
     ]
    }
   ],
   "source": [
    "ppi_edge_index = torch.tensor([ppi_edge_start,\n",
    "                           ppi_edge_end], dtype=torch.long)\n",
    "\n",
    "ppi_edge_weight = torch.tensor(ppi_edge_weight, dtype=torch.float)\n",
    "\n",
    "\n",
    "print(ppi_edge_index)\n",
    "print(ppi_edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "qwoqdovlHED9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    1,  ..., 4597, 4597, 4602],\n",
      "        [   0,   79,    1,  ...,  130,  155,   40]])\n",
      "tensor([1.0000, 0.9000, 1.0000,  ..., 0.9430, 0.9380, 0.9990])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-72-ebd3d297f469>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ppi_edge_weight = torch.tensor(ppi_edge_weight, dtype=torch.float).to(device)\n"
     ]
    }
   ],
   "source": [
    "ppi_edge_index = torch.tensor([ppi_edge_start,\n",
    "                           ppi_edge_end], dtype=torch.long).to(device)\n",
    "\n",
    "ppi_edge_weight = torch.tensor(ppi_edge_weight, dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "print(ppi_edge_index)\n",
    "print(ppi_edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "js9AdG-7HED9"
   },
   "outputs": [],
   "source": [
    "torch.cuda.max_split_size_mb=100000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "O_4-pVVfHED-"
   },
   "outputs": [],
   "source": [
    "from torch.nn import LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.nn import GATConv, GATv2Conv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from torch.nn import LayerNorm\n",
    "\n",
    "#MHGAT model\n",
    "class MHGCNNet(torch.nn.Module):\n",
    "    def __init__(self,input_size, pathway_dic_new, num_features_xd=64, num_features_xdout=1, n_output=1, num_features_xt=512,\n",
    "                     embed_dim_drug=128, embed_dim_cell=128, output_dim=256, dropout=0.2, n_heads=4, n_land_genes=4603):\n",
    "        super(MHGCNNet, self).__init__()\n",
    "        self.input_size=input_size\n",
    "        self.n_heads=n_heads\n",
    "        self.output_dim=output_dim\n",
    "        self.pathway_dic_new=pathway_dic_new\n",
    "        self.fnn_list=[]\n",
    "        self.n_land_genes=n_land_genes\n",
    "        self.num_features_xdout=num_features_xdout\n",
    "        #cellline layers\n",
    "\n",
    "        self.ppi_gan1 = GCNConv(1, num_features_xdout)\n",
    "        self.ppi_gan_bn1=nn.BatchNorm1d(1)\n",
    "\n",
    "        self.ppi_gan2 = GATv2Conv(1, num_features_xdout)\n",
    "        self.ppi_gan_bn2=nn.BatchNorm1d(1)\n",
    "\n",
    "        self.celllin1 = nn.Linear(n_land_genes , 256).cpu()\n",
    "        self.cellBN1=BatchNorm1d(256)\n",
    "        self.celllin2 = nn.Linear(256, embed_dim_cell).cpu()\n",
    "        self.cellBN2=BatchNorm1d(embed_dim_cell)\n",
    "\n",
    "        # drug layers\n",
    "        self.druglin1 = nn.Linear(num_drug_fp , 256).cpu()\n",
    "        self.BN1=BatchNorm1d(256)\n",
    "        self.druglin2 = nn.Linear(256, embed_dim_drug).cpu()\n",
    "        self.BN2=BatchNorm1d(embed_dim_drug)\n",
    "\n",
    "        self.celldruglin1 = nn.Linear(embed_dim_drug + embed_dim_cell + 256, 256).cpu()\n",
    "        self.celldruglin2 = nn.Linear(256, 1).cpu()\n",
    "\n",
    "        # activation and regularization\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.linear1 = nn.Linear(output_dim+num_features_xt,10)\n",
    "        self.linear2 = nn.Linear(10,1)\n",
    "\n",
    "        self.BN3=LayerNorm(256)\n",
    "        self.batch_normGAT = nn.BatchNorm1d(n_land_genes)\n",
    "        self.batch_normGAT2 = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "    def forward(self, data, output_vectors, output_embeddings):\n",
    "        x, ppi_edge_index, ppi_edge_attr, drug_fp = data.x, data.ppi_edge_index, data.ppi_edge_weight, data.drug_fp\n",
    "###########################################PPI GCN###################################################\n",
    "        x=x.unsqueeze(2)\n",
    "        x=list(x)\n",
    "        data_list = [Data(x=x_, edge_index=ppi_edge_index, edge_attr=ppi_edge_attr) for x_ in x]\n",
    "        batch = Batch.from_data_list(data_list)\n",
    "# ##################################################################################################\n",
    "\n",
    "        x = F.elu(self.ppi_gan_bn1(self.ppi_gan1(batch.x, batch.edge_index, batch.edge_attr)))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "\n",
    " ################################################################################################\n",
    "        x=x.reshape(-1,self.n_land_genes*self.num_features_xdout)\n",
    "        out_cell = self.cellBN1(self.celllin1(x))\n",
    "        out_cell = F.relu(out_cell)\n",
    "        out_cell = self.cellBN2(self.celllin2(out_cell))\n",
    "        out_cell = F.relu(out_cell)\n",
    "\n",
    "\n",
    "        # drug layers\n",
    "        out_drug = self.BN1(self.druglin1(drug_fp))\n",
    "        out_drug = F.relu(out_drug)\n",
    "        out_drug = self.BN2(self.druglin2(out_drug))\n",
    "        out_drug = F.relu(out_drug)\n",
    "\n",
    "\n",
    "#         print(\"out_cell\", out_cell.shape)\n",
    "#         print(\"out_drug\", out_drug.shape)\n",
    "#         print(\"output_embeddings\", output_embeddings.shape)\n",
    "#         print(\"output_vectors\", output_vectors.shape)\n",
    "        \n",
    "#         if out_cell.shape != (84, 128):\n",
    "            # concat\n",
    "#             print(\"if\")\n",
    "        out = torch.cat((out_cell, out_drug, output_vectors, output_embeddings), 1)\n",
    "        z = F.dropout(self.BN3(self.celldruglin1(out)), p=0.2, training=self.training)\n",
    "        z = F.relu(z)\n",
    "        z=self.celldruglin2(z)\n",
    "\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "kwb7oFHVHED-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "epoch0,mseloss2.139,_pcc0.578\n",
      "mseloss1.429,_pcc0.8541,r20.7178526520729065\n",
      "epoch1,mseloss1.451,_pcc0.8426\n",
      "mseloss1.358,_pcc0.8729,r20.7461032867431641\n",
      "epoch2,mseloss1.393,_pcc0.8561\n",
      "mseloss1.282,_pcc0.8802,r20.7735973000526428\n",
      "epoch3,mseloss1.363,_pcc0.8626\n",
      "mseloss1.275,_pcc0.8841,r20.7757683396339417\n",
      "epoch4,mseloss1.349,_pcc0.8656\n",
      "mseloss1.27,_pcc0.8872,r20.7777178287506104\n",
      "epoch5,mseloss1.326,_pcc0.8705\n",
      "mseloss1.231,_pcc0.8906,r20.7912623882293701\n",
      "epoch6,mseloss1.311,_pcc0.8736\n",
      "mseloss1.255,_pcc0.8936,r20.7825180888175964\n",
      "epoch7,mseloss1.298,_pcc0.8762\n",
      "mseloss1.217,_pcc0.8979,r20.7959712147712708\n",
      "epoch8,mseloss1.282,_pcc0.8795\n",
      "mseloss1.192,_pcc0.9006,r20.8039731979370117\n",
      "epoch9,mseloss1.263,_pcc0.8831\n",
      "mseloss1.185,_pcc0.903,r20.8064086437225342\n",
      "epoch10,mseloss1.246,_pcc0.8863\n",
      "mseloss1.151,_pcc0.9065,r20.8170372843742371\n",
      "epoch11,mseloss1.23,_pcc0.8895\n",
      "mseloss1.122,_pcc0.9094,r20.8261001110076904\n",
      "epoch12,mseloss1.206,_pcc0.894\n",
      "mseloss1.114,_pcc0.9104,r20.8287113904953003\n",
      "epoch13,mseloss1.197,_pcc0.8957\n",
      "mseloss1.141,_pcc0.913,r20.8205123543739319\n",
      "epoch14,mseloss1.192,_pcc0.8966\n",
      "mseloss1.116,_pcc0.9152,r20.8281465768814087\n",
      "epoch15,mseloss1.179,_pcc0.8991\n",
      "mseloss1.106,_pcc0.9167,r20.8316084742546082\n",
      "epoch16,mseloss1.166,_pcc0.9012\n",
      "mseloss1.074,_pcc0.9194,r20.840968906879425\n",
      "epoch17,mseloss1.16,_pcc0.9023\n",
      "mseloss1.052,_pcc0.9212,r20.8474154472351074\n",
      "epoch18,mseloss1.155,_pcc0.9034\n",
      "mseloss1.045,_pcc0.9217,r20.8492385149002075\n",
      "epoch19,mseloss1.145,_pcc0.9052\n",
      "mseloss1.047,_pcc0.9231,r20.8486824631690979\n",
      "epoch20,mseloss1.137,_pcc0.9065\n",
      "mseloss1.029,_pcc0.9242,r20.8539011478424072\n",
      "epoch21,mseloss1.128,_pcc0.908\n",
      "mseloss1.057,_pcc0.9242,r20.8459784388542175\n",
      "epoch22,mseloss1.123,_pcc0.9088\n",
      "mseloss1.027,_pcc0.9262,r20.8544971942901611\n",
      "epoch23,mseloss1.117,_pcc0.9098\n",
      "mseloss1.003,_pcc0.9283,r20.8614012598991394\n",
      "epoch24,mseloss1.11,_pcc0.9111\n",
      "mseloss0.9965,_pcc0.929,r20.8630057573318481\n",
      "epoch25,mseloss1.103,_pcc0.9123\n",
      "mseloss0.9947,_pcc0.9297,r20.8633999824523926\n",
      "epoch26,mseloss1.094,_pcc0.9137\n",
      "mseloss1.001,_pcc0.9299,r20.8621042370796204\n",
      "epoch27,mseloss1.089,_pcc0.9145\n",
      "mseloss0.9864,_pcc0.9315,r20.8657476305961609\n",
      "epoch28,mseloss1.087,_pcc0.9148\n",
      "mseloss0.9795,_pcc0.9328,r20.8676927089691162\n",
      "epoch29,mseloss1.081,_pcc0.9158\n",
      "mseloss0.9688,_pcc0.9332,r20.8706492781639099\n",
      "epoch30,mseloss1.078,_pcc0.9163\n",
      "mseloss0.9647,_pcc0.9341,r20.8715052604675293\n",
      "epoch31,mseloss1.073,_pcc0.917\n",
      "mseloss0.9641,_pcc0.9346,r20.8719211220741272\n",
      "epoch32,mseloss1.059,_pcc0.9194\n",
      "mseloss0.9565,_pcc0.9354,r20.873792827129364\n",
      "epoch33,mseloss1.065,_pcc0.9185\n",
      "mseloss0.9848,_pcc0.9361,r20.8658273816108704\n",
      "epoch34,mseloss1.059,_pcc0.9193\n",
      "mseloss0.9719,_pcc0.937,r20.8697453737258911\n",
      "epoch35,mseloss1.053,_pcc0.9204\n",
      "mseloss0.9587,_pcc0.9372,r20.8732419013977051\n",
      "epoch36,mseloss1.048,_pcc0.9211\n",
      "mseloss0.9389,_pcc0.9387,r20.878481924533844\n",
      "epoch37,mseloss1.032,_pcc0.9236\n",
      "mseloss0.9578,_pcc0.9389,r20.8735270500183105\n",
      "epoch38,mseloss1.029,_pcc0.9241\n",
      "mseloss0.921,_pcc0.9397,r20.8827448487281799\n",
      "epoch39,mseloss1.029,_pcc0.9242\n",
      "mseloss0.9381,_pcc0.9401,r20.8784602284431458\n",
      "epoch40,mseloss1.024,_pcc0.9248\n",
      "mseloss0.9313,_pcc0.9412,r20.8804153203964233\n",
      "epoch41,mseloss1.014,_pcc0.9262\n",
      "mseloss0.9035,_pcc0.9423,r20.8875510692596436\n",
      "epoch42,mseloss1.009,_pcc0.9272\n",
      "mseloss0.9016,_pcc0.9434,r20.8879485130310059\n",
      "epoch43,mseloss1.007,_pcc0.9274\n",
      "mseloss0.918,_pcc0.944,r20.8839421272277832\n",
      "epoch44,mseloss1.008,_pcc0.9273\n",
      "mseloss0.8879,_pcc0.9446,r20.8911103010177612\n",
      "epoch45,mseloss1.003,_pcc0.9281\n",
      "mseloss0.8765,_pcc0.9456,r20.8940055966377258\n",
      "epoch46,mseloss0.9953,_pcc0.9292\n",
      "mseloss0.8734,_pcc0.9466,r20.8946628570556641\n",
      "epoch47,mseloss0.9881,_pcc0.9301\n",
      "mseloss0.8735,_pcc0.9475,r20.8949171304702759\n",
      "epoch48,mseloss0.9875,_pcc0.9303\n",
      "mseloss0.9145,_pcc0.9476,r20.8849048018455505\n",
      "epoch49,mseloss0.977,_pcc0.9318\n",
      "mseloss0.8543,_pcc0.9486,r20.8993973731994629\n",
      "epoch50,mseloss0.9753,_pcc0.9321\n",
      "mseloss0.8488,_pcc0.9492,r20.9006602764129639\n",
      "epoch51,mseloss0.9736,_pcc0.9324\n",
      "mseloss0.8453,_pcc0.9506,r20.9014579653739929\n",
      "epoch52,mseloss0.9635,_pcc0.9338\n",
      "mseloss0.8338,_pcc0.951,r20.9041499495506287\n",
      "epoch53,mseloss0.9497,_pcc0.9358\n",
      "mseloss0.8392,_pcc0.9516,r20.902992844581604\n",
      "epoch54,mseloss0.9604,_pcc0.9342\n",
      "mseloss0.8292,_pcc0.9526,r20.9052186012268066\n",
      "epoch55,mseloss0.9624,_pcc0.9339\n",
      "mseloss0.9375,_pcc0.9508,r20.8790594339370728\n",
      "epoch56,mseloss0.9456,_pcc0.9364\n",
      "mseloss0.8071,_pcc0.9541,r20.9100916981697083\n",
      "epoch57,mseloss0.9402,_pcc0.9371\n",
      "mseloss0.8276,_pcc0.9538,r20.9055310487747192\n",
      "epoch58,mseloss0.9373,_pcc0.9374\n",
      "mseloss0.8292,_pcc0.9547,r20.9052253365516663\n",
      "epoch59,mseloss0.9281,_pcc0.9387\n",
      "mseloss0.7985,_pcc0.9556,r20.9121378660202026\n",
      "epoch60,mseloss0.9278,_pcc0.9388\n",
      "mseloss0.7887,_pcc0.9566,r20.9142460823059082\n",
      "epoch61,mseloss0.9193,_pcc0.94\n",
      "mseloss0.7999,_pcc0.9566,r20.9118154048919678\n",
      "epoch62,mseloss0.9203,_pcc0.9398\n",
      "mseloss0.7744,_pcc0.9578,r20.9172947406768799\n",
      "epoch63,mseloss0.908,_pcc0.9414\n",
      "mseloss0.791,_pcc0.9573,r20.9138290286064148\n",
      "epoch64,mseloss0.9059,_pcc0.9417\n",
      "mseloss0.7643,_pcc0.9593,r20.919399082660675\n",
      "epoch65,mseloss0.8972,_pcc0.9429\n",
      "mseloss0.7734,_pcc0.9591,r20.9175301790237427\n",
      "epoch66,mseloss0.903,_pcc0.9421\n",
      "mseloss0.7555,_pcc0.9603,r20.9212966561317444\n",
      "epoch67,mseloss0.8933,_pcc0.9434\n",
      "mseloss0.7556,_pcc0.9604,r20.9212871789932251\n",
      "epoch68,mseloss0.8879,_pcc0.944\n",
      "mseloss0.766,_pcc0.9612,r20.9190608859062195\n",
      "epoch69,mseloss0.8858,_pcc0.9444\n",
      "mseloss0.7476,_pcc0.9623,r20.9229910373687744\n",
      "epoch70,mseloss0.8894,_pcc0.9438\n",
      "mseloss0.7439,_pcc0.9626,r20.9236910343170166\n",
      "epoch71,mseloss0.8867,_pcc0.9443\n",
      "mseloss0.7265,_pcc0.9635,r20.9273043274879456\n",
      "epoch72,mseloss0.8686,_pcc0.9466\n",
      "mseloss0.7263,_pcc0.9636,r20.9274005889892578\n",
      "epoch73,mseloss0.8709,_pcc0.9463\n",
      "mseloss0.7255,_pcc0.9645,r20.9274776577949524\n",
      "epoch74,mseloss0.871,_pcc0.9462\n",
      "mseloss0.7096,_pcc0.9649,r20.9305347204208374\n",
      "epoch75,mseloss0.8637,_pcc0.9472\n",
      "mseloss0.7049,_pcc0.9652,r20.9314981698989868\n",
      "epoch76,mseloss0.8515,_pcc0.9487\n",
      "mseloss0.7051,_pcc0.966,r20.9314879179000854\n",
      "epoch77,mseloss0.856,_pcc0.9482\n",
      "mseloss0.6917,_pcc0.9668,r20.934039294719696\n",
      "epoch78,mseloss0.8551,_pcc0.9483\n",
      "mseloss0.6991,_pcc0.9668,r20.9326571822166443\n",
      "epoch79,mseloss0.8506,_pcc0.9489\n",
      "mseloss0.6895,_pcc0.9674,r20.9343944787979126\n",
      "epoch80,mseloss0.8371,_pcc0.9505\n",
      "mseloss0.695,_pcc0.9684,r20.9332329630851746\n",
      "epoch81,mseloss0.8469,_pcc0.9493\n",
      "mseloss0.679,_pcc0.9683,r20.9365305304527283\n",
      "epoch82,mseloss0.8372,_pcc0.9505\n",
      "mseloss0.6777,_pcc0.969,r20.9367763996124268\n",
      "epoch83,mseloss0.826,_pcc0.9518\n",
      "mseloss0.6689,_pcc0.9693,r20.9383125305175781\n",
      "epoch84,mseloss0.8366,_pcc0.9505\n",
      "mseloss0.6896,_pcc0.9693,r20.9344632625579834\n",
      "epoch85,mseloss0.8262,_pcc0.9519\n",
      "mseloss0.6585,_pcc0.9702,r20.9402236342430115\n",
      "epoch86,mseloss0.8204,_pcc0.9525\n",
      "mseloss0.652,_pcc0.9705,r20.9414596557617188\n",
      "epoch87,mseloss0.8127,_pcc0.9534\n",
      "mseloss0.6586,_pcc0.9705,r20.9402216672897339\n",
      "epoch88,mseloss0.8181,_pcc0.9527\n",
      "mseloss0.6417,_pcc0.9713,r20.9432446956634521\n",
      "epoch89,mseloss0.819,_pcc0.9526\n",
      "mseloss0.6376,_pcc0.9716,r20.943959653377533\n",
      "epoch90,mseloss0.8033,_pcc0.9545\n",
      "mseloss0.6298,_pcc0.9724,r20.9453948140144348\n",
      "epoch91,mseloss0.8009,_pcc0.9548\n",
      "mseloss0.6302,_pcc0.9726,r20.9451735019683838\n",
      "epoch92,mseloss0.8004,_pcc0.9549\n",
      "mseloss0.6394,_pcc0.9726,r20.9437065124511719\n",
      "epoch93,mseloss0.7941,_pcc0.9555\n",
      "mseloss0.6249,_pcc0.9733,r20.9461697936058044\n",
      "epoch94,mseloss0.7877,_pcc0.9564\n",
      "mseloss0.6637,_pcc0.9736,r20.9393846392631531\n",
      "epoch95,mseloss0.7974,_pcc0.9551\n",
      "mseloss0.6085,_pcc0.9741,r20.9488827586174011\n",
      "epoch96,mseloss0.7832,_pcc0.9568\n",
      "mseloss0.6059,_pcc0.9748,r20.9494771957397461\n",
      "epoch97,mseloss0.7861,_pcc0.9565\n",
      "mseloss0.6733,_pcc0.9734,r20.9375901222229004\n",
      "epoch98,mseloss0.7854,_pcc0.9566\n",
      "mseloss0.61,_pcc0.9751,r20.9486828446388245\n",
      "epoch99,mseloss0.7843,_pcc0.9567\n",
      "mseloss0.6121,_pcc0.975,r20.9483468532562256\n",
      "0.6059\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('run')\n",
    "#     batch_size = 512\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.0001#0.0001\n",
    "    type = 'set'\n",
    "    ID = '1'\n",
    "    train_dataset = DrugCellAUC('train_set1.csv')\n",
    "#     train_dataset = DrugCellAUC('/workspace/HiDRA/HiDRA_MHA/Dataset/set/train_set1.csv')\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True) #TRUE\n",
    "\n",
    "    model = MHGCNNet(input_size, pathway_dic_new).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0000001)\n",
    "    #optimizer_sgd = optim.SGD(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    optimizer_sgd = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "\n",
    "    test_dataset = DrugCellAUC('test_set1.csv')\n",
    "    batch_size = 128\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True) #True\n",
    "    min_test_mseloss=10.0\n",
    "    it_count=0\n",
    "    valloss=[]\n",
    "    trloss=[]\n",
    "#     min_r=''\n",
    "#     min_r2=0.0\n",
    "\n",
    "\n",
    "    MSE_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(100):\n",
    "        _loss = 0\n",
    "        outs = []\n",
    "        aucs = []\n",
    "        for batch_idx, (cell_drug_genes, auc) in enumerate(train_data_loader):\n",
    "            auc = Variable(auc.float()).cpu() #[512]\n",
    "            batch_num = batch_idx + 1\n",
    "            cell_drug_genes=np.array(cell_drug_genes.cpu())\n",
    "            cell_genes=cell_drug_genes[:,:num_cellline_genes]\n",
    "            drug_fp=cell_drug_genes[:,num_cellline_genes:]\n",
    "            cell_genes=torch.from_numpy(cell_genes).float().to(device)\n",
    "            drug_fp=torch.from_numpy(drug_fp).float().to(device)\n",
    "            data = Data(x=cell_genes,  ppi_edge_index=ppi_edge_index, ppi_edge_weight=ppi_edge_weight, drug_fp=drug_fp)\n",
    "            \n",
    "            out = model(data, output_vectors.detach(), output_embeddings.detach())\n",
    "            optimizer.zero_grad()  #uncomment\n",
    "            loss = torch.sqrt(criterion(torch.squeeze(out) + TINY, auc)) #float value\n",
    "            if epoch % 1 == 0:\n",
    "                _out = torch.squeeze(out) #[512]\n",
    "                for item in range(len(auc)):\n",
    "                    outs.append(_out.data[item]) #[512]\n",
    "                    aucs.append(auc.data[item]) #[512]\n",
    "                _loss += loss.item()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "        if epoch % 1 == 0:\n",
    "            cacul_rer = cacul_r3.cacul_r(outs,aucs)\n",
    "            r =\"{0:.4}\".format(cacul_rer.cacul())\n",
    "#             print(\"_loss\", _loss)\n",
    "            epoch_loss = \"{0:.4}\".format(_loss/batch_num)\n",
    "            print ('epoch{},mseloss{},_pcc{}'.format(epoch,epoch_loss,r))\n",
    "            train_mseloss = epoch_loss\n",
    "            train_r = r\n",
    "            MSE_loss.append(train_mseloss)\n",
    "        with open('MSELoss_{}_{}.txt'.format(batch_size,learning_rate),'w') as f:\n",
    "            for eachloss in range(len(MSE_loss)):\n",
    "                f.write('{}\\n'.format(MSE_loss[eachloss]))\n",
    "        torch.save(model, 'gcn_{}_{}.pt'.format(batch_size, learning_rate))\n",
    "        test_model = torch.load('gcn_{}_{}.pt'.format(batch_size, learning_rate), weights_only=False).cpu()\n",
    "        test_model.eval()\n",
    "        _loss = 0\n",
    "        outs = []\n",
    "        aucs = []\n",
    "        for batch_idx, (cell_drug_genes, auc) in enumerate(test_data_loader):\n",
    "            auc = Variable(auc.float()).cpu() #[512]\n",
    "            batch_num = batch_idx + 1\n",
    "            cell_drug_genes=np.array(cell_drug_genes.cpu())\n",
    "            cell_genes=cell_drug_genes[:,:num_cellline_genes]\n",
    "            drug_fp=cell_drug_genes[:,num_cellline_genes:]\n",
    "            cell_genes=torch.from_numpy(cell_genes).float().to(device)\n",
    "            drug_fp=torch.from_numpy(drug_fp).float().to(device)\n",
    "            data = Data(x=cell_genes,  ppi_edge_index=ppi_edge_index, ppi_edge_weight=ppi_edge_weight, drug_fp=drug_fp)\n",
    "            with torch.no_grad():\n",
    "                out = test_model(data, output_vectors.detach(), output_embeddings.detach())\n",
    "            _out = torch.squeeze(out)\n",
    "            for item in range(len(auc)):\n",
    "                outs.append(_out.data[item])\n",
    "                aucs.append(auc.data[item])\n",
    "            loss = torch.sqrt(criterion(torch.squeeze(out) + TINY, auc))\n",
    "            _loss += loss\n",
    "        cacul_rer = cacul_r3.cacul_r(outs,aucs)\n",
    "        r =\"{0:.4}\".format(cacul_rer.cacul())\n",
    "        test_r = r\n",
    "        test_mseloss = \"{0:.4}\".format(_loss.data/batch_num)\n",
    "        target = torch.tensor(aucs)\n",
    "        preds = torch.tensor(outs)\n",
    "        r2= r2_score(preds, target)\n",
    "        print ('mseloss{},_pcc{},r2{}'.format(test_mseloss,r,r2))\n",
    "        valloss.append(test_mseloss)\n",
    "        time_end = time.time()\n",
    "        if(float(test_mseloss)<float(min_test_mseloss)):\n",
    "\n",
    "            torch.save(model, 'PPIENS_GCN.pt')\n",
    "            min_test_mseloss=float(test_mseloss)\n",
    "#             min_r=r\n",
    "#             min_r2=r2\n",
    "            it_count=0\n",
    "        else:\n",
    "            if(it_count>200):\n",
    "                break\n",
    "            else:\n",
    "                it_count=it_count+1\n",
    "print(min_test_mseloss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
